package i_DataStructures;

public class F_BigOnotation {

	/*
	 * O(n) : how code slows as data grows
	 * 
	 * in order of increasing time : 
	 * 
	 * O(1) : constant time : always takes constant amount of time regardless how much data size is there
	 * 		random access of an element in array, inserting at the beginning of linked list
	 * O(log n) : log of n time : increasingly less time to complete, as data size increases, algo becomes more efficient
	 * 		binary search
	 * O(n) : linear time : time taken is proportional to data size
	 * 		looping through elements in an array, searching trough a linked list
	 * O(n log n) : quasi linear time : gradually slows down as we use larger data set, else is very much similar to linear
	 * 		quick sort, merge sort, heap sort
	 * O(n ^ 2) : n squared time : quadratic time : way more time for more data size
	 * 		insertion sort, selection sort, bubble sort
	 * O(n!) : factorial time : extremely slow
	 * 		traveling salesman problem
	 */
}
